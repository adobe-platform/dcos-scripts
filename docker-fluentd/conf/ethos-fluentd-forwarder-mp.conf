<source>
  type monitor_agent
  bind 0.0.0.0
  port 24220
</source>

<source>
  @type tcp
  @id input_from_tcp
  @label @mainstream
  port 5170
  format json
  tag local.tcp
</source>

<source>
  @type syslog
  @id input_from_syslog_tcp
  @label @mainstream
  port 5140
  protocol_type tcp
  format syslog
  time_format 1 %Y-%m-%dT%H:%M:%S.%L%z
  tag local.syslog
</source>

<source>
  @type systemd
  @id ingest_from_journald
  @label @mainstream
  path "#{ENV['FLUENTD_SYSTEMD_PATH']}"
  filters "#{ENV['FLUENTD_SYSTEMD_FILTERS']}"
  pos_file "#{ENV['FLUENTD_SYSTEMD_POS_FILE']}"
  read_from_head "#{ENV['FLUENTD_SYSTEMD_READ_FROM_HEAD']}"
  strip_underscores "#{ENV['FLUENTD_SYSTEMD_STRIP_UNDERSCORES']}"
  tag local.systemlog
</source>

<source>
  @type tail
  @id ingest_from_tail
  @label @mainstream
  read_from_head "#{ENV['FLUENTD_TAIL_READ_FROM_HEAD']}"
  refresh_interval "#{ENV['FLUENTD_TAIL_REFRESH_INTERVAL']}"
  enable_watch_timer "#{ENV['FLUENTD_TAIL_ENABLE_WATCH_TIMER']}"
  rotate_wait "#{ENV['FLUENTD_TAIL_ROTATE_WAIT']}"
  path "#{ENV['FLUENTD_TAIL_EXECUTOR_LOG_PATH']}/**/std*"
  exclude_path "#{ENV['FLUENTD_TAIL_EXECUTOR_LOG_PATH']}/**/std*.*"
  pos_file "#{ENV['FLUENTD_TAIL_EXECUTOR_LOG_PATH']}/fluentd.pos"
  path_key "#{ENV['FLUENTD_TAIL_PATH_KEY']}"
  format none
  tag local.executorlog
</source>

<label @mainstream>

  # Drop logs with blank lines
  <filter local.executorlog>
    @type grep
    @id blank_line_filter
    regexp1 message .+
  </filter>
  <filter local.systemlog>
    @type grep
    @id blank_line_filter2
    regexp1 MESSAGE .+
  </filter>

  # Drop logs coming from the Docker journald driver (we use executor logs instead)
  <filter local.systemlog>
    @type grep
    @id docker_journald_filter
    exclude1 CONTAINER_NAME .+
  </filter>

  # Set the timestamp and source_host for all local logs
  <match local.systemlog>
    @type record_reformer
    @id set_host_and_timestamp_field
    tag ${tag_parts[1]}
    <record>
      timestamp ${(Time.now.to_f).to_s}
      source_host "#{ENV['MESOS_CLUSTER']},#{ENV['ethos_role']},#{ENV['zone']},#{ENV['HOST']}"
    </record>
  </match>

  <match local.executorlog>
    @type record_reformer
    @id set_record_metadata
    tag reformed.${tag_parts[1]}
    <record>
      timestamp ${(Time.now.to_f).to_s}
      source_host "#{ENV['MESOS_CLUSTER']},#{ENV['ethos_role']},#{ENV['zone']},#{ENV['HOST']}"
      CONTAINER_NAME ${"mesos-" + record['file_path'].to_s.split("/")[6] + "." + record['file_path'].to_s.split("/")[12]}
    </record>
  </match>

  # Run applog tagged records through the ethos plugin to see if they have the logging metadata in the docker label
  <filter reformed.executorlog>
    @type ethos_filter
    @id get_ethos_metadata
    merge_json_message "#{ENV['FLUENTD_ETHOSPLUGIN_MERGE_JSON']}"
    cache_size "#{ENV['FLUENTD_ETHOSPLUGIN_CACHE_SIZE']}"
    cache_ttl "#{ENV['FLUENTD_ETHOSPLUGIN_CACHE_TTL']}"
    get_container_id_tag "#{ENV['FLUENTD_ETHOSPLUGIN_GET_TAG_FLAG']}"
    container_id_attr "#{ENV['FLUENTD_ETHOSPLUGIN_CONTAINER_FIELD']}"
  </filter>

  # Any records that have the ETHOS_LOGGING attribute are applogs, anything with file_path are executor logs.  Everything else is a system log.
  <match reformed.executorlog>
    @type rewrite_tag_filter
    @id split_app_logs
    rewriterule1 ETHOS_LOGGING .+ applog
    rewriterule2 file_path .+ executorlog
  </match>

  # Discard all executor logs except for those specific to the ETHOS cluster
  <filter executorlog>
    @type grep
    @id filter_mesos_executor_logs
    regexp1 file_path executors\/(agentfill|apigateway|aqua-agent|aqua-ethos-setup|aqua-gateway|aqua-web|booster|capcom|docker-cleanup|dsn|ecr-login|etcd|ethos-datadog|ethos-fluentd|ethos-splunkforwarder|feature-flipper-cache|flight-director|jenkins|iam-role-iptables|iam-role-proxy|klam-ssh|mercury|moonbeam|moonmaker|orca|prometheus|sidekick|skopos)
  </filter>

  <match *>
    @type copy
    <store>
      @type forward
      @id output_to_fluentd_collector
      expire_dns_cache "{#ENV['FLUENTD_FORWARD_DNS_TTL']}"
      send_timeout "#{ENV['FLUENTD_FORWARD_SEND_TIMEOUT']}"
      recover_wait "#{ENV['FLUENTD_FORWARD_RECOVER_WAIT']}"
      heartbeat_interval "#{ENV['FLUENTD_FORWARD_HEARTBEAT_INTERVAL']}"
      heartbeat_type "#{ENV['FLUENTD_FORWARD_HEARTBEAT_TYPE']}"
      phi_failure_detector "#{ENV['FLUENTD_FORWARD_PHI_FAILURE_DETECTOR']}"
      phi_threshold "#{ENV['FLUENTD_FORWARD_PHI_THRESHOLD']}"
      hard_timeout "#{ENV['FLUENTD_FORWARD_HARD_TIMEOUT']}"
      buffer_type "#{ENV['FLUENTD_FORWARD_BUFFER_TYPE']}"
      buffer_path "#{ENV['FLUENTD_FORWARD_BUFFER_PATH']}/forward/"
      buffer_queue_limit "#{ENV['FLUENTD_FORWARD_BUFFER_QUEUE_LIMIT']}"
      buffer_chunk_limit "#{ENV['FLUENTD_FORWARD_BUFFER_CHUNK_LIMIT']}"
      flush_interval "#{ENV['FLUENTD_FORWARD_FLUSH_INTERVAL']}"
      flush_at_shutdown "#{ENV['FLUENTD_FORWARD_FLUSH_AT_SHUTDOWN']}"
      retry_wait "#{ENV['FLUENTD_FORWARD_RETRY_WAIT']}"
      max_retry_wait "#{ENV['FLUENTD_FORWARD_MAX_RETRY_WAIT']}"
      retry_limit "#{ENV['FLUENTD_FORWARD_RETRY_LIMIT']}"
      disable_retry_limit "#{ENV['FLUENTD_FORWARD_DISABLE_RETRY_LIMIT']}"
      num_threads "#{ENV['FLUENTD_FORWARD_NUM_THREADS']}"

      <server>
        name fluentd_collector_lb
        host "#{ENV['FLUENTD_COLLECTOR_LB']}"
        port "#{ENV['FLUENTD_COLLECTOR_PORT_MP_1']}"
        weight "#{ENV['FLUENTD_COLLECTOR_WEIGHT']}"
      </server>
      <server>
        name fluentd_collector_lb
        host "#{ENV['FLUENTD_COLLECTOR_LB']}"
        port "#{ENV['FLUENTD_COLLECTOR_PORT_MP_2']}"
        weight "#{ENV['FLUENTD_COLLECTOR_WEIGHT']}"
      </server>
      <secondary>
        @type s3
        s3_bucket "#{ENV['FLUENTD_AWS_S3_BUCKET']}"
        s3_region us-east-1
        path "#{ENV['FLUENTD_AWS_S3_BUCKET_PATH']}"
        s3_object_key_format "%{path}forwarder/#{ENV['HOST']}_%{time_slice}_%{index}.%{file_extension}"
        store_as text
        buffer_type "#{ENV['FLUENTD_FORWARD_BUFFER_TYPE']}"
        buffer_path "#{ENV['FLUENTD_FORWARD_BUFFER_PATH']}/s3/"
        buffer_queue_limit "#{ENV['FLUENTD_FORWARD_BUFFER_QUEUE_LIMIT']}" 
        buffer_chunk_limit "#{ENV['FLUENTD_FORWARD_BUFFER_CHUNK_LIMIT']}"
        flush_interval "#{ENV['FLUENTD_FORWARD_FLUSH_INTERVAL']}" 
        flush_at_shutdown "#{ENV['FLUENTD_FORWARD_FLUSH_AT_SHUTDOWN']}"
        retry_limit "#{ENV['FLUENTD_FORWARD_RETRY_LIMIT']}"
        <assume_role_credentials>
         role_arn "#{ENV['FLUENTD_AWS_IAM_ROLE']}"
         role_session_name fluentd-s3
        </assume_role_credentials>
      </secondary>
    </store>
    <store>
      @type flowcounter
      @id forwarder_metrics
      @label @counts
      aggregate tag
      count_keys timestamp
      unit minute
    </store>
  </match>
</label>

<label @counts>
  <match **>
    @type stdout
  </match>
</label>
